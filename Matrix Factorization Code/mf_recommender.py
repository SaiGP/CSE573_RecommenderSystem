# -*- coding: utf-8 -*-
"""mf_recommender.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yu5hXAF4-vWJDHHQXW6bO4onrWf5cOpJ
"""

import json
import os

import numpy as np
import pandas as pd
from sklearn.decomposition import randomized_svd as SVD

# from google.colab import drive
# drive.mount('/content/drive')
drive_path = "./"


def get_data(file):
    print("building rating list...")
    data_dict = {"users": [], "items": [], "rating": []}

    try:
        f = open(file, "r")

        data = json.load(f)
        for d in data:
            data_dict["users"].append(d["user_id"])
            data_dict["items"].append(d["book_id"])
            data_dict["rating"].append(d["rating"])

        f.close()
    except:
        print("unable to read file" + file)

    return data_dict


def get_items(file):
    print("building items list...")
    items_dict = {"id": [], "title": [], "similar_items":[]}

    try:
        f = open(file, "r")

        text = f.readline()
        while text:
            d = json.loads(text)
            items_dict["id"].append(d["book_id"])
            items_dict["title"].append(d["title"])
            items_dict["similar_items"].append(d["similar_books"])
            text = f.readline()
        f.close()

    except:
        print("unable to read file" + file)

    return items_dict


def get_pivot(data_dict):
    # users = list(set(data_dict["users"]))
    # items = list(set(data_dict["items"]))

    # rating = np.zeros((len(users), len(items)))

    df_data = pd.DataFrame.from_dict(data_dict)
    print(df_data.columns)
    print(df_data.iloc[0])
    print(df_data.head())

    pivot_mat = pd.pivot_table(df_data, index="users", columns="items", values="rating", aggfunc=np.average, fill_value=0)
    '''for r_ind, user in enumerate(users):
        for c_ind, item in enumerate(items):
            rating = 0
            cnt = 0
            for ind, u, it in enumerate(zip(data_dict["users"], data_dict["items"])):
                if u == user and it == item:
                    rating += data_dict["rating"][ind]
                    cnt += 1
            rating[r_ind][c_ind] = rating/cnt'''
    print(pivot_mat.head())
    inp = input("$>")
    pivot_mat.to_pickle('pivot.pk')
    return pivot_mat


def get_item_id(name):
    item_file = drive_path + "books_data.json"
    if os.path.exists(item_file):
        file = open(item_file, "r")
        items = json.load(file)
        file.close()
    else:
        return

    if items["title"].index(name):
      index = items["title"].index(name)
      val = items["id"][index]
    else:
      val = 0
    return val


def get_titles(sim_items, name):
    # item_ids = mat.columns.values.tolist()
    item_file = drive_path + "books_data.json"
    if os.path.exists(item_file):
        file = open(item_file, "r")
        items = json.load(file)
        file.close()
    
    sim_titles = []
    for si in sim_items:
        iid = items["id"].index(si)
        sim_titles.append(items["title"][iid])
        
    n_idx = items["title"].index(name)
    print(items["similar_items"][n_idx])
    return sim_titles


def predict(sim_mat, index, item_id_list, n=10):
    row = sim_mat[index]
    #print(row)
    
    sorted_id = [item_id_list[x] for x,y in sorted(enumerate(row), key = lambda x: x[1], reverse=True) ]
    # print(sorted_id[:n])
    
    return sorted_id[:n]


def main():
    item_file = drive_path + "books_data.json"
    rating_file = drive_path + "ratings.json"
    items = {}
    data = {}

    data_bool = os.path.exists(rating_file)
    if data_bool:
        print("Loading...")
        file = open(rating_file, "r")
        data = json.load(file)
        file.close()

    if not os.path.exists(item_file) or not data_bool:
        print("Preparing data...")
        items = get_items("../book_data.json")
        item_file = open(item_file, "w")
        json.dump(items, item_file)

        data = get_data("../train_data.json")

        data_file = open(rating_file, "w")
        json.dump(data, data_file)
        item_file.close()
        data_file.close()

    print(len(data["users"]))
    n = int(input("enter the number of elements: "))

    data["users"] = data["users"][:n]
    data["items"] = data["items"][:n]
    data["rating"] = data["rating"][:n]


    print("Matrix factorization using SVD")

    if os.path.exists("./vh.out"):
        matrix = np.loadtxt("./vh.out")
        u = np.loadtxt("./user.out")
        s = np.loadtxt("./lft.out")

    else:
        print("generating Pivot table...")
        pivot_mat = get_pivot(data)
        print("perform SVD on pivot table...")
        X = pivot_mat.values.T
        # U, S, V = np.linalg.svd(pivot_mat)
        # write U, S and V to file and read from file.
        # TSVD = SVD(n_components=12, random_state=0)
        u, s, matrix = SVD(X, n_components=15, random_state=None)
        np.savetxt("vh.out", matrix)
        np.savetxt("user.out", u)
        np.savetxt("lft.out", s)

    print(matrix.shape)

    inp = input("press N to exit: ")
    if inp.upper() == "N":
      return

    if os.path.exists(drive_path + "sim_mat.py"):
        print("Loading correlation matrix")
        file = open(drive_path + "sim_mat.py", "r")
        sim_mat = np.loadtxt(file, delimiter=',', unpack= True)
        file.close()

    else:
      print("Creating correlation Matrix:")
      sim_mat = np.corrcoef(matrix.T)
      file = open(drive_path + "sim_mat.py", "w")
      np.savetxt(file, sim_mat, delimiter=',')
      file.close()

    print(sim_mat.shape)
    inp = input("press N to exit: ")
    if inp.upper() == "N":
      return

    name = "Bunny Drop, Vol. 2"
    print("Finding books similar to " + name +":\n")

    id = get_item_id(name)

    if id == 0:
      print("ERROR:" + name + " not in the list")
      return
      
    item_id_list = pivot_mat.columns.to_list()
    index = item_id_list.index(id)
    sim_items = predict(sim_mat, index, item_id_list)

    print("the top 10 similar books are: ")
    print(sim_items)
    print(get_titles(sim_items, name))


main()
