'''
Utility class with some helper functions
'''

import pandas as pd
import numpy as np
import random
import os
import tensorflow as tf
from pathlib import Path

class Util(object):

    def read_data(self, folder):
        '''
        Function to read data required to
        build the recommender system
        '''

        print("Reading the data")
        base_path = Path(__file__).parent
        ratings = pd.read_csv((base_path / "data/new_ratings.csv").resolve(), index_col=None)
        to_read = pd.read_csv((base_path / "data/to_read_books.csv").resolve())
        books = pd.read_csv((base_path / "data/book_data.csv").resolve())
        book_ids = pd.read_csv((base_path / "data/book_ids.csv").resolve())

        return ratings, to_read, books, book_ids
        # return ratings, book_ids

    def clean_subset(self, ratings, num_rows):
        '''
        Function to clean and subset the data according
        to individual machine power
        '''
        print("Extracting num_rows from ratings")
        temp = ratings.sort_values(by=['user_id'], ascending=True)
        ratings = temp.iloc[:num_rows, :]
        return ratings

    def preprocess(self, ratings):
        '''
        Preprocess data for feeding into the network
        '''
        print("Preprocessing the dataset")
        ratings = ratings.reset_index(drop=True)
        ratings['List Index'] = ratings.index
        readers_group = ratings.groupby("user_id")

        total = []
        for readerID, curReader in readers_group:
            temp = np.zeros(len(ratings))
            for num, book in curReader.iterrows():
                temp[book['List Index']] = book['rating']/5.0
            total.append(temp)

        return total

    def split_data(self, total_data):
        '''
        Function to split into training and validation sets
        '''
        print("Free energy required, dividing into train and validation sets")
        random.shuffle(total_data)
        n = len(total_data)
        print("Total size of the data is: {0}".format(n))
        size_train = int(n * 0.75)
        X_train = total_data[:size_train]
        X_valid = total_data[size_train:]
        print("Size of the training data is: {0}".format(len(X_train)))
        print("Size of the validation data is: {0}".format(len(X_valid)))
        return X_train, X_valid

    def free_energy(self, v_sample, W, vb, hb):
        '''
        Function to compute the free energy
        '''
        wx_b = np.dot(v_sample, W) + hb
        vbias_term = np.dot(v_sample, vb)
        hidden_term = np.sum(np.log(1 + np.exp(wx_b)), axis = 1)
        return -hidden_term - vbias_term
